{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0df8103-6072-455e-9ca2-be2535f56251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train folder exists: True\n",
      "Validation folder exists: True\n",
      "Test folder exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set dataset path (modify this according to your folder location)\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\archive\"\n",
    "# Check if dataset folders exist\n",
    "print(\"Train folder exists:\", os.path.exists(os.path.join(dataset_path, \"train\")))\n",
    "print(\"Validation folder exists:\", os.path.exists(os.path.join(dataset_path, \"validation\")))\n",
    "print(\"Test folder exists:\", os.path.exists(os.path.join(dataset_path, \"testing\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a4b344-ed00-4e2c-8935-7561bef9151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\anaconda\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in e:\\anaconda\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9607d5eb-3891-44cd-a6f9-6a0117ba7f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train videos: 1200\n",
      "Validation videos: 100\n",
      "Test videos: 670\n",
      "Sample Train Video Folder: ['-4wsuPCjDBc_5_15', '-7KMZQEsJW4_205_208', '-8y1Q0rA3n8_108_115', '-8y1Q0rA3n8_95_102', '-9CUm-2cui8_39_44']\n"
     ]
    }
   ],
   "source": [
    "# Define paths for train, val, and test\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "val_path = os.path.join(dataset_path, \"validation\")\n",
    "test_path = os.path.join(dataset_path, \"testing\")\n",
    "\n",
    "# Get all video frame folders\n",
    "train_videos = sorted(os.listdir(train_path))\n",
    "val_videos = sorted(os.listdir(val_path))\n",
    "test_videos = sorted(os.listdir(test_path))\n",
    "\n",
    "print(f\"Train videos: {len(train_videos)}\")\n",
    "print(f\"Validation videos: {len(val_videos)}\")\n",
    "print(f\"Test videos: {len(test_videos)}\")\n",
    "print(\"Sample Train Video Folder:\", train_videos[:5])  # Show first 5 video IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea549dee-4c7e-4981-b1a8-0369f188abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda\\lib\\site-packages (2.6.0+cpu)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: torchvision in e:\\anaconda\\lib\\site-packages (0.21.0+cpu)\n",
      "Requirement already satisfied: torchaudio in e:\\anaconda\\lib\\site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\anaconda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\anaconda\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\anaconda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51b950a-90c3-4ae4-b9d0-2e450b3ee580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames shape: (16, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_video_frames(video_folder, max_frames=16):\n",
    "    \"\"\"\n",
    "    Loads a limited number of frames from a given video folder.\n",
    "    Converts frames into a NumPy array.\n",
    "    \"\"\"\n",
    "    frame_paths = sorted(os.listdir(video_folder))[:max_frames]  # Select first `max_frames` frames\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_paths:\n",
    "        frame_path = os.path.join(video_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is not None:\n",
    "            frame = cv2.resize(frame, (224, 224))  # Resize for CNN input\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            frames.append(frame)\n",
    "\n",
    "    return np.array(frames)  # Shape: (num_frames, 224, 224, 3)\n",
    "\n",
    "# Example usage\n",
    "video_frames = load_video_frames(r\"C:\\Users\\hp\\Downloads\\archive\\train\\bQJQGoJF7_k_145_153\")\n",
    "print(\"Frames shape:\", video_frames.shape)  # Expected Output: (16, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07500ad-ae76-4bd6-ba0e-87813fa482c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785ccdd5-0052-452c-a44b-5feb45ad0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (16, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load Pre-trained CNN Model (VGG16)\n",
    "cnn_model = models.vgg16(pretrained=True)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # Remove last FC layer\n",
    "cnn_model.eval()\n",
    "\n",
    "# Define Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_cnn_features(video_folder, max_frames=16):\n",
    "    frames = load_video_frames(video_folder, max_frames)\n",
    "    frame_tensors = torch.stack([transform(frame) for frame in frames])  # Convert frames to tensors\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(frame_tensors)\n",
    "\n",
    "    return features.squeeze().numpy()  # Shape: (16, 512, 7, 7)\n",
    "\n",
    "# Example usage\n",
    "video_features = extract_cnn_features(r\"C:\\Users\\hp\\Downloads\\archive\\train\\bQJQGoJF7_k_145_153\")\n",
    "print(\"Feature shape:\", video_features.shape)  # Expected Output: (16, 512, 7, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a380e665-4e54-4e39-879c-a536d8d796a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Alphanumeric                                     Sentence\n",
      "0  -4wsuPCjDBc_5_15  a squirrel is eating a peanut in it s shell\n",
      "1  -4wsuPCjDBc_5_15                         a chipmunk is eating\n",
      "2  -4wsuPCjDBc_5_15                a chipmunk is eating a peanut\n",
      "3  -4wsuPCjDBc_5_15                   a chipmunk is eating a nut\n",
      "4  -4wsuPCjDBc_5_15                   a squirrel is eating a nut\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = r\"C:\\Users\\hp\\Downloads\\archive\\captions.csv\"  # Update with the correct path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3a16ac-3c67-4486-8bed-f89bbba62eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Alphanumeric                                           Sentence\n",
      "0     -4wsuPCjDBc_5_15  [a squirrel is eating a peanut in it s shell, ...\n",
      "1  -7KMZQEsJW4_205_208  [a man demonstrating how to clean a flower, a ...\n",
      "2  -8y1Q0rA3n8_108_115  [a man slices through a two liter plastic bott...\n",
      "3   -8y1Q0rA3n8_95_102  [a man with a sword runs ands stabs a cardboar...\n",
      "4    -9CUm-2cui8_39_44  [a woman puts four okra in a pan of boiling wa...\n"
     ]
    }
   ],
   "source": [
    "# Group captions by video_id\n",
    "grouped_df = df.groupby(\"Alphanumeric\")[\"Sentence\"].apply(list).reset_index()\n",
    "\n",
    "# Display first few rows\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e024a00c-0605-4083-a1b6-89e494145342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Videos: ['bQJQGoJF7_k_162_169', 'bSIjZ75a50s_286_304', 'bSrpvMSuhPM_17_31', 'bXsKw3TOQXs_30_55', 'b_BuSVZwq6M_1_9', 'bb6V0Grtub4_174_185', 'bkazguPsusc_74_85', 'bmOy6p87TWI_26_35', 'bmvD4HlPFxg_20_27', 'bmxIurBrW5s_51_70', 'bnN_o0Hkn3M_73_80', 'bqMmyY1ImkI_0_14', 'bruzcOyIGeg_4_12', 'btuxO-C2IzE_64_72', 'btxCxlO1Euc_1_20', 'buJ5HDCinrM_150_166', 'bxDlC7YV5is_0_12', 'bxjFqtfJlMs_18_27', 'c2MwqFYVE7A_40_45', 'c2a0GcoJAjw_107_129', 'c2a0GcoJAjw_52_73', 'c51L6ZxZGjQ_137_154', 'c53HKs39i28_26_35', 'c75SIlAjfjg_6_14', 'c76tShLfQb0_74_81', 'cCmnN96zIeQ_14_24', 'cFzSEIGrEfA_0_24', 'cJOZp2ZftCw_1_12', 'cLNrpO6wBk4_37_47', 'cM55xNJ_pfU_1_20', 'cR2yi-JnGcQ_8_16', 'cSDkshD2ME0_11_14', 'cSDkshD2ME0_12_15', 'cUW_bXll6YM_390_395', 'cUW_bXll6YM_462_469', 'cWOPC2kt_IA_8_16', 'c_-eFL7Sfw4_19_35', 'c_XV7nPoRg8_2_12', 'ceOXCFUmxzA_100_110', 'clKtfGBVI1I_15_28', 'clpgffj3sUw_1_12', 'cmQ3SiIaWy4_4_20', 'cnsjm3fNEec_4_10', 'crfrKqFp0Zg_15_25', 'cs33MNhpRNw_16_21', 'cwkjJrGpoaU_30_41', 'd-2C_N5anww_1_3', 'd1zdJO3CqVw_1_35', 'd4AGWnHJcaY_6_19', 'd7Gs0uGFLh0_5_13', 'd7eGypGOlOc_13_22', 'dEn5E-TNezw_13_23', 'dJ3ba9zwx6c_5_15', 'dJCtOz32dnw_40_60', 'dJEoDaA6VXc_1_19', 'dMH0bHeiRNg_3_14', 'dP15zlyra3c_0_10', 'dQmaVQZz7EE_1_18', 'dZBIdRGKRhM_13_32', 'd_BWuttLRFM_42_52', 'dabI5gfaFm4_19_25', 'dc4UltkRJsw_53_59', 'dfOuTx66bJU_11_14', 'dfOuTx66bJU_34_39', 'dhxE9CNeVeY_0_12', 'dmyz_f8Sx14_56_66', 'dq7agmFWkq0_5_9', 'drsPD5fI1IA_170_180', 'dtn0PuxgfkM_0_5', 'dtwXtwJByYk_5_14', 'e-j59PqJjSM_163_173', 'e-j59PqJjSM_264_277', 'e-j59PqJjSM_405_416', 'e-j59PqJjSM_50_98', 'e-sf-hyrkTs_20_35', 'e3XkmpNcSt4_8_19', 'e40bBP0_AbE_64_67', 'e4QGnppJ-ys_6_14', 'e996zZ0uV_A_152_163', 'e996zZ0uV_A_196_204', 'e996zZ0uV_A_68_72', 'eKtsMfmQ_0s_61_68', 'ePujnD4qJO0_62_77', 'eTnlw7v8ea0_36_50', 'eVSQiPbepXg_44_49', 'eVSQiPbepXg_83_93', 'eZLxohGP4IE_147_158', 'eZLxohGP4IE_15_25', 'eZLxohGP4IE_190_201', 'eb-Zp4pJLKk_2_19', 'ecVwxlXc1PQ_0_12', 'ecm9gf2Pgkc_1_24', 'edqyq4Q-7uU_103_109', 'eiyuac7hA4A_4_47', 'ejgwQqCHN1E_7_12', 'elQqQfux7Po_12_22', 'emblM4a76jg_5_15', 'eoP-SCgYM2w_49_60', 'eroAmLZ85DI_28_35', 'eyMYc-37Sk4_0_10', 'eyhzdC936uk_15_27', 'f-24IxG9ijw_25_40', 'f9Won2JpOEU_60_80', 'f9_bP219ehQ_63_70', 'fBA_lxUiwSg_2_4', 'fEsrO_poIUg_161_168', 'fF89MasBFLw_321_326', 'fGc6_D0JEIQ_31_46', 'fHfpMUDrQCs_17_31', 'fIaLVw_Gc_w_99_109', 'fJr2evLANsE_0_10', 'fKqBnl8D1Qo_5_44', 'fMFvOgb4k6E_35_43', 'fMXfphSi6Yw_7_12', 'fVWUaH2mCt4_1_7', 'fX5G_JwPlLo_640_660', 'fY0lZTWlBAg_470_485', 'f_CvW22Eauc_16_23', 'f_GnkweYzzI_35_41', 'fcvW1vr8hAs_104_108', 'fcvW1vr8hAs_96_102', 'fd7Ky1lEPT8_40_50', 'fgWFxFg7-GU_10_26', 'ficwZQYmRLE_5_20', 'fjDvKHkmxs0_119_126', 'fjDvKHkmxs0_72_87', 'fkONJEgTNJY_25_35', 'fnpp8v9NbmY_181_188', 'fqly5kyO2MI_10_20', 'fr9H1WLcF1A_141_148', 'fr9H1WLcF1A_256_261', 'fr9H1WLcF1A_326_336', 'fvBs0xpEZhQ_10_30', 'fw8qvK67jYY_50_97', 'g1Gldu1KS44_8_14', 'g2IYQq7IkXc_124_132', 'g2IYQq7IkXc_23_32', 'g36ho6UrBz0_5_20', 'g8LUhxR-6Wg_0_8', 'g9aZcaEg7iY_0_9', 'gCra4qOrjFw_1_17', 'gGDtPJzh_0s_30_45', 'gHyXstpe_N8_116_125', 'gHyXstpe_N8_140_150', 'gHyXstpe_N8_95_100', 'gHzws6FpuNE_10_12', 'gIvetX_oXeI_85_90', 'gMqKUPeTAkg_17_30', 'gWRRHV7DLV0_21_31', 'gXVaC3gBWbc_22_30', 'gbUhorqLCzU_10_23', 'gbW9f8xydks_0_10', 'gbbRwBZuhzI_26_40', 'ge7OOILJA6U_20_25', 'ggWzbEFC-RE_1_11', 'ggic669elLM_200_215', 'ghynaoVNwZc_1_20', 'giLxPCgLLqg_9_19', 'gjVBEJGHrXk_26_38', 'glii-kazad8_21_29', 'glrijRGnmc0_211_215', 'gnEE6oWoz7U_124_132', 'gp8XjWSoP2k_0_10', 'gqSOvUH_njE_151_155', 'gqxpGOHUH9k_113_119', 'gtIz1u8g1F0_3_13', 'gtixLEvO2Us_0_6', 'gvVsgOK1iJw_32_38', 'gyOVZz7kXyM_1_10', 'h0JvF9vpqx8_213_223', 'h0JvF9vpqx8_36_42', 'hEOGZoYSvT4_82_86', 'hFERWnoc-nU_0_12', 'hJFBXHtxKIc_118_123', 'hJFBXHtxKIc_163_168', 'hJFBXHtxKIc_204_209', 'hJFBXHtxKIc_225_230', 'hJFBXHtxKIc_286_291', 'hJFBXHtxKIc_298_303', 'hJFBXHtxKIc_310_315', 'hJFBXHtxKIc_317_322', 'hJuqBDw_TT4_105_112', 'hJuqBDw_TT4_14_25', 'hM3jzlyNIpc_0_10', 'hNECyt6Bo0A_5_10', 'hNOzHvsEmg4_31_36', 'hNPZmTlY_3Q_0_8', 'hPyU5KjpWVc_0_35', 'hReROJQpSow_24_30', 'hSgGBHbJrmE_0_17', 'hW8TKz2Aea4_40_50', 'hW8TKz2Aea4_5_12', 'hWhKdXcqYeU_3_12', 'hXn7D6-AAMA_0_9', 'haJn6k5zVnE_1_23', 'hbE29pZh76I_3_8', 'hcCLIzzB1jQ_1_7', 'hkkmKk9LcQk_36_43', 'hksxtbcS780_7_14', 'hoinj6vyQ2g_8_16', 'ht2oIYBSoI0_9_21', 'htWPOGTagec_2_18', 'htry5uxX0-Y_45_52', 'hxZ-5wELSJM_0_12', 'i2GgBwlwV0c_24_31', 'i2sRHf9m5KM_28_42', 'i3cHNObcEh8_0_10', 'i3fd4nE8OCI_174_181', 'iCiGjZEV7VI_65_75', 'iEW-EkPQywU_61_83', 'iLr7ZHAq1ro_7_11', 'iTA0rWPE4nY_17_23', 'iUYWdCxvJCI_2_14', 'iarsmqA3dck_19_25', 'ibSwITK4jjQ_14_24', 'idRc_KkInds_0_6', 'idXJu0BQRvo_2_6', 'ifS2nXfCyYo_4_34', 'inLBPVG8oEU_18_24', 'inzk2fTUe1w_1_15', 'io2dbV-Qbus_215_247', 'itxzpFW1z7E_22_36', 'iuqVpMdb1NM_35_43', 'iwpnUHFhjWc_84_94', 'iwpnUHFhjWc_9_14', 'iyAoiWeD53k_120_127', 'izU1dDwnuMY_80_92', 'j1Z890_Q3so_131_138', 'j2Dhf-xFUxU_13_20', 'j2Dhf-xFUxU_20_29', 'j2sOMdilDWU_87_97', 'j4dMnAPZu70_11_18', 'j4dMnAPZu70_12_17', 'j7xz1nos-xc_10_20', 'jCplbayVbtw_10_20', 'jCplbayVbtw_28_38', 'jD4o_Lmy6bU_117_137', 'jDFn-1lXJ98_71_80', 'jI58q6rcNLc_8_18', 'jLgmCY1fEE8_16_26', 'jMO3jGQeqyk_3_6', 'jPBxl9gFqNY_110_117', 'jTaLGh_MKCM_5_20', 'jTnrm338_KY_34_42', 'jW77z3-SrO4_56_63', 'jZ8X8e7eRVk_24_27', 'jbzaMtPYtl8_48_58', 'jcIrD7rNvTM_10_21', 'jcRCn7MeSbo_71_82', 'jdAbpLooDgM_10_15', 'jfrrO5K_vKM_55_65', 'jjl2ZMdFCsw_130_142', 'jjl2ZMdFCsw_17_35', 'jlahRlo4jlU_30_36', 'jmoT2we_rqo_0_5', 'jsEUFYhiqxU_121_128', 'jv-eV6jR3Qw_7_12', 'jvxUeT1Nlb8_100_115', 'jxdubZzQrio_33_46', 'k-SWy-sU8cE_5_10', 'k06Ge9ANKM8_5_16', 'k4hhWYtaQ14_0_10', 'k5OKBX2e7xA_19_32', 'k8l4ETsylVY_9_18', 'k9Brw_0gncU_14_33', 'kBMsuhDvg88_45_64', 'kBjUDCyDCuI_20_26', 'kEGmZDpZ_RE_248_293', 'kEGmZDpZ_RE_295_330', 'kEGmZDpZ_RE_352_370', 'kI6MWZrl8v8_149_161', 'kIZanu909lw_67_80', 'kJY5BRCNAs4_3_6', 'kKGehSw5ht8_39_45', 'kNHivduxQWg_0_14', 'kRNHJSc4AXE_220_228', 'kSzS_lFtJDk_55_70', 'kWLNZzuo3do_145_151', 'kWLNZzuo3do_147_153', 'kWLNZzuo3do_152_164', 'kWLNZzuo3do_154_165', 'kWLNZzuo3do_167_181', 'kWLNZzuo3do_17_23', 'kWLNZzuo3do_192_196', 'kWLNZzuo3do_206_213', 'kWLNZzuo3do_217_222', 'kWLNZzuo3do_222_227', 'kWLNZzuo3do_228_232', 'kWLNZzuo3do_24_31', 'kWLNZzuo3do_251_260', 'kWLNZzuo3do_25_32', 'kWLNZzuo3do_262_270', 'kWLNZzuo3do_31_37', 'kWLNZzuo3do_38_42', 'kWLNZzuo3do_38_47', 'kWLNZzuo3do_48_53', 'kWLNZzuo3do_56_62', 'kWLNZzuo3do_76_80', 'kWLNZzuo3do_77_83', 'kWLNZzuo3do_86_93', 'kZfBt5me3Pg_2_7', 'kk3TIio1-Uw_5_14', 'klFyrnrUSck_13_19', 'klFyrnrUSck_25_36', 'klFyrnrUSck_42_46', 'klFyrnrUSck_63_73', 'klFyrnrUSck_79_85', 'klFyrnrUSck_87_100', 'klteYv1Uv9A_27_33', 'kquB3rIgfGk_197_202', 'kquB3rIgfGk_525_532', 'kquB3rIgfGk_537_544', 'kquB3rIgfGk_640_645', 'krAk8WPZRL4_207_212', 'kuNQpRTc-hA_126_135', 'kzyFBlNRohs_82_88', 'l57mQZvDaL4_10_30', 'l5JJ2n2ggiQ_319_327', 'lAznAeFFldg_6_10', 'lB1UPJ4leqs_0_6', 'lB1UPJ4leqs_1_6', 'lFdg5CWMTt0_24_28', 'lFyPUgJCmtU_100_110', 'lGk1MA6YP-M_36_48', 'lKADopH3qFY_0_10', 'lKpGc3SCSVw_12_20', 'lR8RrUBhCQg_5_15', 'lSnWhsmlGec_5_10', 'labytsb3gfI_146_154', 'lb8J2zCQTlo_3_8', 'lc9bA-hvqHU_1_6', 'lcu-DwrnYY8_2_5', 'lexLAjh8fPA_27_31', 'lfGlDg47How_110_115', 'lfGlDg47How_361_367', 'lfGlDg47How_93_98', 'ljGcQocjSs4_38_60', 'lm0z7eLsbbw_9_23', 'lmCrIZeob4w_23_26', 'lo4KcsBN--A_0_10', 'lrZxpneS6Gk_0_12', 'lsanQj2yacs_102_108', 'lsanQj2yacs_80_85', 'lv8d_qLLqsk_1_20', 'lvFYUmDSOvU_34_38', 'lw7pTwpx0K0_38_48', 'm1NR0uNNs5Y_104_110', 'm1NR0uNNs5Y_123_129', 'm1NR0uNNs5Y_160_166', 'm1NR0uNNs5Y_192_198', 'm1NR0uNNs5Y_224_230', 'm1NR0uNNs5Y_273_280', 'm1NR0uNNs5Y_57_64', 'm1NR0uNNs5Y_73_78', 'm1NR0uNNs5Y_88_94', 'm1c04pCYGxA_57_64', 'm4D72WXFd8s_557_564', 'm7x8uIdg2XU_67_73', 'mCrRHP4LFmo_24_40', 'mF6ijhSrbBQ_32_40', 'mFCf8lLXrUc_25_35', 'mFCf8lLXrUc_36_57', 'mHv4iJ9Yr1g_10_16', 'mJ9eRvxjLc4_0_16', 'mOZkcBcWR8o_6_12', 'mYzajpeAWuA_100_112', 'mZVPkPqwzR4_38_45', 'mbesJaS6vwg_187_195', 'me1D1WZ0yNM_120_124', 'mfJjIOfj6D8_3_10', 'mmSQTI6gMNQ_120_128', 'mmSQTI6gMNQ_15_21', 'msCidKHOh74_392_399', 'msCidKHOh74_410_418', 'mtrCf667KDk_134_176', 'muI1BFsdbdo_33_45', 'mv89psg6zh4_33_46', 'n016q1w8Q30_2_11', 'n2NLoLNecgI_168_178', 'n6U-TGahwvs_100_110', 'nBFhvrAOFqY_23_29', 'nBFhvrAOFqY_89_103', 'nBJV56WUDng_38_47', 'nCtZFOYAlvQ_44_49', 'nHZsE7T7hwI_13_23', 'nLvX-erABqY_67_72', 'nLz0QuerH1c_8_15', 'nMBSDpB3WB8_5_14', 'nPj6EcVGoUY_7_15', 'nS6oQxX_Qi8_2_12', 'nTUONeDqhdk_10_15', 'nTasT5h0LEg_12_14', 'nTasT5h0LEg_40_43', 'nULE40HEWpA_5_11', 'nV3Wv8iHp4U_0_38', 'nYwbAb0QvBE_195_210', 'nZSFn51l3hc_318_326', 'nZSFn51l3hc_480_485', 'nZSFn51l3hc_660_666', 'n_Z0-giaspE_168_193', 'n_Z0-giaspE_270_278', 'n_Z0-giaspE_379_387', 'n_Z0-giaspE_437_447', 'n_Z0-giaspE_62_78', 'nau1vCzyFQ4_37_54', 'nb12bAaKzvA_0_10', 'nc0fVlaTYEs_34_44', 'nc8hwLaOyZU_1_19', 'nd0ToNwccl4_12_17', 'ngHDYzhDBk4_24_29', 'ngHDYzhDBk4_5_14', 'nhm_APPwhWk_6_12', 'nlU3crMsbWI_19_23', 'nohvigNMsbo_199_207', 'nq4hG6qgyPs_184_195', 'nq4hG6qgyPs_240_251', 'nq4hG6qgyPs_370_377', 'nrZyPuRd5pU_85_92', 'nwk4m329bLw_2_10', 'o2X6UCaNqKA_27_36', 'o4OsYxsNGMI_77_82', 'o4pL7FObqds_137_147', 'o4pL7FObqds_243_263', 'o4pL7FObqds_72_78', 'oBt257I-pL0_0_10', 'oDcd2JbOyzg_38_55', 'oDcd2JbOyzg_85_98', 'oFUsn1owAbs_158_168', 'oG6LLGi_n48_51_55', 'oRBgVOiZVsc_16_22', 'oSnYUfCGiCA_7_17', 'o_mWZWcm2r4_10_15', 'o_mWZWcm2r4_47_54', 'oeaVXK2GAyc_4_21', 'ogcqFaNbah4_475_487', 'ok4cM6WTA5E_120_133', 'ok4cM6WTA5E_142_150', 'ok4cM6WTA5E_178_184', 'omGWjiwxcTE_18_23', 'omIPdpxg--4_39_46', 'onW5hJXnI5s_10_16', 'onW5hJXnI5s_126_133', 'onxE6PpEXes_8_25', 'otLEUwHao_E_140_151', 'otvx5OZHTJc_1_22', 'p3J3TAdKAYQ_0_10', 'p69Q8lTkZTc_21_29', 'p69d3UBdpR8_98_109', 'p6T3XrnYtFk_4_13', 'p6cg2jWI34M_34_42', 'p7IAuvd87hQ_12_19', 'p9g06ktIkJg_4_11', 'pDvzOLRLjPc_0_8', 'pFSoWsocv0g_8_17', 'pGCRurvXQGM_45_56', 'pGsU4FekJQM_10_18', 'pNelR-nHz7g_68_90', 'pQYEZTwSVbQ_12_18', 'pRpeEdMmmQ0_1_18', 'pRpeEdMmmQ0_65_70', 'pUPKsHTDZTo_70_85', 'pW9DFPqoIsI_26_50', 'pcjuCotJYj8_50_62', 'pdrBPJYfTC8_33_39', 'pfQPRXcihkI_127_138', 'pfQPRXcihkI_135_144', 'pfQPRXcihkI_160_184', 'pmEKZ6yVewc_0_10', 'po2tcrG6KzM_2_8', 'pptYu3YQnxY_160_170', 'pqTWUzehCUM_42_47', 'psXeA8sSYdI_25_30', 'ptHkvYrH9fY_2_10', 'puineN1UMto_25_29', 'pzq5fPfsPZg_145_160', 'pzq5fPfsPZg_29_33', 'pzq5fPfsPZg_51_57', 'q-JHcsqJXWY_0_8', 'q-a6NEotUX8_5_10', 'q3I3R_gqy8M_34_37', 'q3I3R_gqy8M_38_42', 'q3I3R_gqy8M_73_79', 'q5ZRMvjzhXQ_15_29', 'q6vz80UkVtw_0_7', 'q7pOFn8s4zc_263_273', 'q7pOFn8s4zc_27_36', 'q8t7iSGAKik_11_31', 'q8t7iSGAKik_57_74', 'q9ew_nITQWY_54_62', 'qBFSt85-xqk_15_20', 'qDjtN7xxNr4_44_51', 'qIXs7fUoLIg_1_11', 'qIk_Dz5XE5E_104_109', 'qLwgb3F0aPU_298_305', 'qNjeEx92rTA_281_299', 'qOiN__I1-Zo_2_8', 'qPXynwa_2iM_15_25', 'qRoxNXm7INc_58_66', 'qeKX-N1nKiM_0_5', 'qeKX-N1nKiM_106_115', 'qeKX-N1nKiM_123_130', 'qeKX-N1nKiM_133_142', 'qeKX-N1nKiM_37_43', 'qeKX-N1nKiM_52_59', 'qeKX-N1nKiM_68_72', 'qeKX-N1nKiM_74_77', 'qew09qQgMAg_22_27', 'qhknaG9ifbs_122_127', 'qqYysi3qotc_148_195', 'qvSxiVV7jhw_0_15', 'qvg9eM4Hmzk_1_9', 'qvg9eM4Hmzk_4_10', 'qypmR4O1Gwk_0_10', 'qzQzooI4BqU_5_15', 'r0E-0ntoNWo_20_30', 'r0rmrbTb7fU_98_109', 'r2PM0om2El8_18_25', 'r2oI9Y-3wAo_21_28', 'r4qv_BNlQNk_119_124', 'r4qv_BNlQNk_93_98', 'rKF0ZW34FRk_41_54', 'rNSAmHPYHjA_60_73', 'rOic25PnIx8_1_3', 'rQuNYxNmA6M_0_4', 'rV5VmhY3-Sw_65_76', 'rVFJzN20jhQ_27_32', 'rXZy-PHtnxg_8_42', 'ri5AyXzxb4o_201_215', 'rl1rVk_xIOs_1_16', 'rlQ2kW-FvMk_66_79', 'rnawC5C8gSI_82_90', 'rq2p5ML8-WI_63_69', 'ruNrdmjcNTc_0_5', 'ruoHOXo2PRQ_2_20', 'rw9h_574HxE_127_133', 'rw9h_574HxE_13_18', 'rw9h_574HxE_161_166', 'rw9h_574HxE_229_236', 'rw9h_574HxE_251_254', 'rw9h_574HxE_59_66', 'rw9h_574HxE_70_74', 'rwHT2SuNOi8_195_201', 'rwHT2SuNOi8_240_255', 'ry7AUQtuwdU_4_39', 's-QQWRdF-5Y_19_28', 's-XjRDsYuzU_0_12', 's-dSFyz_5Ww_13_23', 's-dSFyz_5Ww_31_41', 's0hwEUC5emA_127_132', 's1ZABV7AQdA_38_48', 's20OlIRK340_125_138', 's20OlIRK340_147_174', 's6QwbmWbSmw_18_24', 's7znbqra118_91_97', 's80J2dAUUyI_33_43', 's8utHZYTNTs_35_42', 's9TklvyLFyI_177_191', 'sBjr8UJOpsQ_149_169', 'sBjr8UJOpsQ_181_195', 'sFExO_PW22s_10_18', 'sJC7E06IBXI_49_59', 'sJSmRik2c-c_1_7', 'sMscRb9TcQE_146_161', 'sRKQfxxEP4M_117_125', 'sT5Bzt9w354_11_34', 'sTMlQSbAGfE_0_12', 'sWqi41wyXcQ_68_79', 'sXyjCgR0rAc_0_11', 'sZf3VDsdDPM_107_114', 's_ldnx8_etY_32_54', 'sb1dX5xAFvk_10_17', 'seTkGZlEU64_81_110', 'shPymuahrsc_5_12', 'sm0OYD0NSbQ_51_59', 'suj4VNfZz5E_33_50', 'sv5YlZspb30_10_20', 'swJ0zhVJ8DU_15_21', 'swKrHEeOj9c_4_8', 't3VPeyYL-fI_35_39', 't4aPGtx7e6k_0_10', 't4vP-cXXWkY_14_20', 't8Nf1MK7lts_0_10', 'tBj4Ny19vfQ_54_59', 'tHLiYTS9Iz8_1_16', 'tIMDKdMnNYM_266_273', 'tJHUH9tpqPg_113_118', 'tPkZK-PzeQE_10_28', 'tYQ7O6V0Fvk_20_55', 'tYh4iDFgmEE_10_14', 'tYh4iDFgmEE_50_54', 'tZmDWltBziM_42_47', 'tZmDWltBziM_70_80', 'tcxhOGyrCtI_15_21', 'tmAX2PnRCY0_284_292', 'tn-Hoz4KbkE_89_93', 'tn1d5DmdMqY_15_28', 'toE0QYZzJKE_1_8', 'tqxRDVKtkSY_30_45', 'tzd3AYTZq0U_0_6', 'u4T76jsPin0_0_11', 'u4kMN1jamdM_10_20', 'u9E9HpuJQ7U_29_43', 'u9prcUCHlqM_235_241', 'u9prcUCHlqM_503_511', 'u9prcUCHlqM_73_80', 'uAaWVeaYLdQ_1_12', 'uB9zRlV47qA_17_23', 'uGDuIyfJXXg_23_33', 'uH8ObB_dyOk_159_166', 'uJPupV4oLZ0_4_12', 'uO7Eysrs8_k_106_114', 'uO7Eysrs8_k_80_90', 'uVPnDJKt1M0_0_6', 'uZEGu-TA2cU_42_58', 'u_6tre9_99Q_13_25', 'ub-aYLzCF_Q_1_10', 'ufFT2BWh3BQ_0_8', 'uiLr9bdOL0M_23_30', 'ul9Xvjt83eI_111_120', 'ulPvRmNfXK4_96_100', 'umjc1CkO4JA_290_305', 'unhiT2D6WvE_0_20', 'uppFvcVwqqY_5_15', 'uqVCk2oDpSE_194_200', 'urNX3e1Wbc8_30_38', 'urXDqw3S34I_12_17', 'uxEhH6MPH28_69_85', 'uy0HNWto0UY_18_25', 'v-9Gx0gJmfo_26_32', 'v-9Gx0gJmfo_91_99', 'v4_AzQSnmY4_40_55', 'v5CeGLEnVFE_0_8', 'v7NpKUVqjpI_23_40', 'v7iIZXtpIb8_5_15', 'vDhEpqfhVI0_0_8', 'vE1gvaM3iAs_39_46', 'vMoOpQQy6sI_22_55', 'vRC9sBNt9vs_10_16', 'vZa13vJugGU_0_30', 'v_tGw5gwlEw_136_152', 'veE0E79dEEc_18_45', 'vfktGc_qx-w_2_18', 'vloe_60s_dk_0_9', 'vpR0L3sIvoo_15_49', 'vub04F8CWng_32_41', 'vulNlhUI6m0_7_27', 'vuvpbeQak9Q_23_29', 'vz71JKcpeUU_0_10', 'w28TljSqtW8_64_75', 'w9mqbwOIkVg_6_12', 'wFPmKChNrhU_3_11', 'wFX6bXLbHW4_83_90', 'wLUH7qA_6sA_90_115', 'wNv74rvkAw8_30_40', 'wON-YuA1GjA_3_63', 'wSwwS_0MKEc_68_78', 'wX-Bl25Htag_104_115', 'wgrrQwLdME8_0_10', 'wgrrQwLdME8_66_74', 'wjH72cZ0GLM_1_10', 'wkgGxsuNVSg_34_41', 'wn9rDTZj-m4_8_18', 'wpUT0DNB3qs_9_19', 'wsj_dzz33Ko_31_41', 'wzfkC2TjdeQ_0_31', 'x1i0UOssll8_141_151', 'x68Djm_Q0GA_0_10', 'x8Ul09tk6zk_0_8', 'xBW_uR3kGr4_42_55', 'xBePrplM4OA_6_18', 'xCFCXzDUGjY_5_9', 'xEDCfcMZlZY_37_41', 'xEDCfcMZlZY_91_100', 'xGdoi3W3Z4o_2_40', 'xOQn1z_oWDY_30_39', 'xPR0xFgCAZY_17_27', 'xSmfK498DjI_1_20', 'xTd_IdIcB4s_2_10', 'xXlWsBhFvis_6_10', 'x_7BrCQdVUs_172_177', 'x_8RiVI6rH8_41_54', 'xaPepCVepCg_35_46', 'xb-Nacm-pKc_78_82', 'xdhLQCYQ-nQ_50_63', 'xfRIRSWy0y0_10_20', 'xgIIcPSh4EU_0_6', 'xkNDE1JL6Z8_50_59', 'xlPyHMkpaQY_1_7', 'xpOYXbMDDBY_1_20', 'xtbsD3PUua4_174_185', 'xtbsD3PUua4_84_94', 'xxHx6s_DbUo_121_128', 'xxHx6s_DbUo_158_161', 'xxHx6s_DbUo_162_165', 'xxHx6s_DbUo_173_177', 'xxHx6s_DbUo_182_186', 'xxHx6s_DbUo_202_207', 'xxHx6s_DbUo_216_222', 'xxHx6s_DbUo_240_248', 'xxHx6s_DbUo_32_36', 'xxHx6s_DbUo_36_40', 'xxHx6s_DbUo_41_44', 'xxHx6s_DbUo_49_56', 'xxHx6s_DbUo_57_61', 'xxHx6s_DbUo_82_86', 'xxHx6s_DbUo_98_101', 'xy9LLUUZ6ic_50_60', 'y8SDRc4IOjs_94_99', 'yAD_TS5L2d4_4_11', 'yBK02O1Oewc_20_35', 'yC4eEuURH8c_19_28', 'yFPHhRat6bc_160_210', 'yId1rg5-ac0_40_50', 'yNy9jTeolUk_8_12', 'yOnRm3TP6hM_0_12', 'yPNFVj-pISU_105_115', 'yREFkmrrYiw_51_57', 'yU5sxW9bErQ_0_17', 'yYA7YXIKbg4_9_14', 'ybVb3t560oY_0_9', 'yd8jh9QYfEs_4_10', 'yfMTsYcLt10_0_7', 'yg4aNiO1JnI_111_114', 'ymC2bNi6-Is_9_19', 'ysTmUTQ5wZE_17_45', 'yvfhk1kwKls_103_113', 'ywHBKayhyvQ_19_28', 'ywMLb2VfHbI_13_20', 'yyxtyCaEVqk_250_264', 'yyxtyCaEVqk_321_328', 'yyxtyCaEVqk_329_360', 'z0Si1XxMibg_0_30', 'z0zb--BOhDY_16_22', 'z1PEyzk4ADU_8_18', 'z2kUc8wp9l8_40_46', 'z8dcUzdi2bw_3_16', 'z9qbQX4J_2g_0_14', 'zBrC1GmA0Qg_26_33', 'zCf8NWJ8kzA_47_52', 'zFIn8DeV5PM_20_33', 'zH4v_DClIoc_3_28', 'zHy7pM0U49w_103_109', 'zHy7pM0U49w_110_116', 'zMg9dChF97A_12_38', 'zS50h-a8RTg_3_9', 'zSPBC8EO6dY_122_126', 'zSPBC8EO6dY_132_140', 'zSPBC8EO6dY_64_73', 'zSPBC8EO6dY_97_110', 'zTn-nNj5Bng_61_77', 'zTn-nNj5Bng_8_19', 'zWVQImPY2Cc_27_44', 'zYcY4mjLpxU_104_118', 'zYcY4mjLpxU_45_55', 'z_qf7tOnHVg_81_89', 'za-9mBZyNfQ_330_336', 'zbAk0gX7kas_16_24', 'zfQOH4UGU_I_1_10', 'zhLcONtNkew_16_21', 'zkTn5Ef1Oig_70_75', 'zkTn5Ef1Oig_71_75', 'zlS1_zBYluY_15_21', 'zpgW7m7_LZw_2_15', 'zr9OeyfLPPY_4_9', 'zuYZ5kPatJE_78_116', 'zulPFoY64wE_26_33', 'zv2RIbUsnSw_159_162', 'zv2RIbUsnSw_335_341', 'zxB4dFJhHR8_1_9', 'zzit5b_-ukg_5_20']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\archive\"\n",
    "\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "\n",
    "# List all video frame folders\n",
    "train_videos = sorted(os.listdir(train_path))\n",
    "\n",
    "# Check if all video IDs exist\n",
    "missing_videos = [vid for vid in grouped_df[\"Alphanumeric\"] if vid not in train_videos]\n",
    "print(f\"Missing Videos: {missing_videos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e9cab-9925-48d4-91aa-f63733555d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Tokenize captions\n",
    "grouped_df[\"tokenized_captions\"] = grouped_df[\"caption\"].apply(lambda captions: [word_tokenize(c.lower()) for c in captions])\n",
    "\n",
    "# Build Vocabulary\n",
    "word_counts = Counter()\n",
    "for caption_list in grouped_df[\"tokenized_captions\"]:\n",
    "    for caption in caption_list:\n",
    "        word_counts.update(caption)\n",
    "\n",
    "# Create a mapping of words to indices\n",
    "word_to_index = {word: i+1 for i, (word, _) in enumerate(word_counts.most_common(5000))}\n",
    "word_to_index[\"<start>\"] = 5001\n",
    "word_to_index[\"<end>\"] = 5002\n",
    "word_to_index[\"<pad>\"] = 0\n",
    "\n",
    "# Convert captions to sequences\n",
    "def caption_to_sequence(caption):\n",
    "    return [word_to_index.get(word, 0) for word in caption]\n",
    "\n",
    "grouped_df[\"caption_sequences\"] = grouped_df[\"tokenized_captions\"].apply(lambda caption_list: [caption_to_sequence(c) for c in caption_list])\n",
    "\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf80c45-9270-40dc-823a-c883f26895eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load extracted CNN features\n",
    "with open(\"train_features.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)\n",
    "\n",
    "# Ensure features match captions\n",
    "for video_id in grouped_df[\"video_id\"]:\n",
    "    if video_id not in train_features:\n",
    "        print(f\"Missing features for {video_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c102b4-b89c-41c9-aed7-66761067cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CaptioningModel(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, vocab_size, embedding_dim):\n",
    "        super(CaptioningModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim + feature_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, video_features, captions):\n",
    "        embeddings = self.embedding(captions)\n",
    "        inputs = torch.cat((video_features.unsqueeze(1), embeddings), dim=1)\n",
    "        lstm_out, _ = self.lstm(inputs)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# Initialize Model\n",
    "model = CaptioningModel(feature_dim=512*7*7, hidden_dim=512, vocab_size=len(word_to_index), embedding_dim=300)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (simplified)\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(torch.randn(1, 512*7*7), torch.randint(0, 5000, (1, 10)))  \n",
    "    loss = criterion(outputs.view(-1, len(word_to_index)), torch.randint(0, 5000, (10,)))  \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c7c7b-376e-48be-bdde-53220c63adcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e4d2f-bdb2-4f29-811b-7d82ac08d7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
